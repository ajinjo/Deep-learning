{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4327d34",
   "metadata": {},
   "source": [
    "## 순환신경망 (Recurrent Neural Network : RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39ba16",
   "metadata": {},
   "source": [
    "RNN (Recurrent Neural Network : 순환 신경망)\n",
    "- DFNN 시계열 데이터 처리의 한계점을 해결하기 위한 신경망\n",
    "- 유닛 간 연결이 순환적 구조를 이룸\n",
    "- 신경망 내부에 상태를 저장할 수 있게 함으로써\n",
    "- 내부의 메모리를 이용해서 시퀀스 형태의 입력 처리\n",
    "\n",
    "- 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을\n",
    "- 출력층 방향으로 보내면서도\n",
    "- 다시 은닉층의 노드의 다음 계산의 입력으로 보내지는 특징\n",
    "\n",
    "- 문자열, 센서 데이터, 음성인식과 같이\n",
    "- 시간적으로 연속성이 있는 데이터 처리에 용이\n",
    "- 층이 많은 네트워크에서 나타나는 그래디언트 소실 문제(vanishing gradient problem) 발생\n",
    "- 오랜 시간 걸쳐 학습 시 그래디언트가 소실하는 문제 \n",
    "\n",
    "- 여러 개의 데이터가 순서대로 입력되었을 때\n",
    "- 앞서 입력받은 데이터를 잠시 기억해 놓는 방법 사용\n",
    "- 기억된 데이터가 얼마나 중요한지를 판단하여\n",
    "- 별도의 가중치를 줘서 다음 데이터로 넘어감\n",
    "- 모든 입력값에 이 작업을 순서대로 실행하기 때문에\n",
    "- 다음 층으로 넘어가기 전에 같은 층을 순환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#그림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb87b46",
   "metadata": {},
   "source": [
    "예 : 인공 지능 비서에게 '오늘 주가가 몇이야?' 묻는 경우\n",
    "\n",
    "- 순환 부분에서 단어를 하나 처리할 때마다 기억하여\n",
    "- 다음 입력 값의 출력을 결정\n",
    "- 순환 중 앞서 나온 입력에 대한 결과가\n",
    "- 뒤에 나오는 입력 값에 영향을 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af7b49",
   "metadata": {},
   "source": [
    "비슷한 두 문장이 입력되었을 때\n",
    "그 차이를 구별하여 출력 값에 반영\n",
    "입력2의 경우 양쪽 모두 '주가'이지만\n",
    "왼쪽의 주가는 '오늘'을 기준으로 계산\n",
    "오른쪽의 주가는 '내일'을 기준으로 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9cc5b",
   "metadata": {},
   "source": [
    "Long Short-Term Memory (LSTM : 장단기 메모리)\n",
    "- RNN에서 발생하는 그래디언트 소실 문제를 해결하기 위한 제안\n",
    "- 실전에서 응용들은 대부분 이 LSTM을 이용하여 구현\n",
    "- 은닉층의 메모리 셀에 입력 게이트, 망각 게이터, 출력 데이를 추가하여\n",
    "- 불필요한 기억을 지우고, 기억해야 할 것들 설정\n",
    "- 은식 상태를 계산하는 식이\n",
    "- RNN 보다는 조금 더 복잡해졌으면 셀 상태(cell state)라는 값이 추가\n",
    "\n",
    "- RNN이 일반 신경만보다 기울기 소실 문제가 더 많이 발생하고\n",
    "- 이를 보완하기 위한 방법\n",
    "- 즉, 반복되기 전에 다음 층으로 기억된 값을 넘길지 안 넘길지를 관리하는 단계가 하나 더 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b711d4c",
   "metadata": {},
   "source": [
    "RNN의 장점\n",
    "- 입력 값과 출력값을 어떻게 설정하는냐에 따라\n",
    "- 여러 가지 상황에 적용할 수 있다는 것\n",
    "(1) 다수 입력 단일 출력\n",
    "(2) 단일 입력 다수 출력\n",
    "(3) 다수 입력 다수 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71c937",
   "metadata": {},
   "source": [
    "(1) 다수 입력 단일 출력\n",
    "- 예 : 문장을 읽고 뜻을 파악할 때 활용 \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9522111",
   "metadata": {},
   "source": [
    "(2) 단일 입력 다수 출력\n",
    "- 사진의 갭션을 만들 때 활용\n",
    "그림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d96124",
   "metadata": {},
   "source": [
    "(3) 다수 입력 다수 출력\n",
    "- 예 : 문장을 번역할 때 활용\n",
    "그림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8f854",
   "metadata": {},
   "source": [
    "### RNN 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883152b",
   "metadata": {},
   "source": [
    "LSTM을 이용한 로이터 뉴스 카테고리 분류하기\n",
    "- 긴 텍스트를 읽고 이 데이터가 어떤 의미를 지니는지 카테고리로 분류\n",
    "\n",
    "입력된 문장의 의미 파악\n",
    "- 모든 단어를 종합하여 하나의 카테고리로 분류하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f29c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dcf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c288db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 로이터 뉴스 데이터셋 불러오기\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "# 데이터 셋 분리\n",
    "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words=1000, test_split=0.2)\n",
    "\n",
    "# num_words=1000\n",
    "# 훈련 데이터에서 가장 자주 나타나는 단어 1,000개만 사용하겠다는 의미\n",
    "# 드물게 나타나는 단어는 무시\n",
    "# 이렇게 하면 적절한 크기의 벡터 데이터를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67a227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 카테고리\n",
      "8982 학습용 뉴스 기사\n",
      "2246 테스트용 뉴스 기사\n",
      "\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인하기\n",
    "category = np.max(Y_train) + 1\n",
    "\n",
    "print(category, '카테고리')\n",
    "print(len(X_train), '학습용 뉴스 기사')\n",
    "print(len(X_test), '테스트용 뉴스 기사')\n",
    "print()\n",
    "print(X_train[0])\n",
    "\n",
    "# 전처리되어 있음 : 각 단어가 숫자로 변환되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d10e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 : 배열의 길이를 동일하게 맞춤\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=100) = sequence.pad_sequences(X_train, maxlen=100)\n",
    "x_test= sequence.pad_sequences(X_test, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4c187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  15,  17,  12],\n",
       "       [  0,   0,   0, ..., 505,  17,  12],\n",
       "       [ 19, 758,  15, ...,  11,  17,  12],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 407,  17,  12],\n",
       "       [ 88,   2,  72, ..., 364,  17,  12],\n",
       "       [125,   2,  21, ..., 113,  17,  12]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "872fc8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5,   2,   7, ..., 510,  17,  12],\n",
       "       [652, 194,   2, ..., 760,  17,  12],\n",
       "       [ 13,  10, 139, ...,   8,  17,  12],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  11,  17,  12],\n",
       "       [  0,   0,   0, ...,   8,  17,  12],\n",
       "       [ 47, 758,  15, ...,   2,  17,  12]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb103cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "y_train = utils.to_categorical(Y_train)\n",
    "y_test = utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa0331c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "276b78f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaccccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 딥러닝 적용\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "# (1) 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 100))\n",
    "model.add(LSTM(100, activation='tanh'))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "# Embedding 층 : 모델 설정 부분의 맨 처음에 있어야 함\n",
    "# 입력 정수에 대해 밀집 벡터로 맵핑\n",
    "# Embedding(단어 총 개수, 기사당 단어 수)\n",
    "\n",
    "# LSTM 층\n",
    "# LSTM(기사당 단어수, 기타 옵션)\n",
    "# LSTM의 활성 함수로는 tanh (하이퍼볼릭 탄젠트) 사용\n",
    "# vanishin gradient 문제를 예방하기 위해\n",
    "# 그래디언트가 최대한 오래 유지될 수 있도록 해주는 역할로\n",
    "# tanh가 적합기 때문 (미분 최대값이 상대적 큼)\n",
    "\n",
    "# (2) 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "              \n",
    "# (3) 모델 실행 (학습)             \n",
    "history = model.fit(x_train, yTrain,\n",
    "                    batch_size=100,\n",
    "                    epochs=20,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "# (4) 모델 평가 (테스트정확도 출력)\n",
    "print('\\n Test Accuracy : %.4f' % (model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8d240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16955cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss와 val_loss 그래프로 표현\n",
    "# 테스트 셋 \n",
    "y_val_loss = history.history['val_loss']\n",
    "# 학습 셋\n",
    "y_loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc671de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 표현\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_val_loss, marker='.', c='red', label='Target_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='Train_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 그래프 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laccuracy와 val_accuracy 그래프로 표현\n",
    "# 테스트 셋 \n",
    "y_val_accuracy = history.history['val_accuracy']\n",
    "# 학습 셋\n",
    "y_accuracy = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e94693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 표현\n",
    "x_len = np.arange(len(y_accuracy))\n",
    "plt.plot(x_len, y_val_accuracy, marker='.', c='red', label='Target_accuracy')\n",
    "plt.plot(x_len, y_accuracy, marker='.', c='blue', label='Train_accuracy')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbb2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HKD_ENV",
   "language": "python",
   "name": "hkdenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
